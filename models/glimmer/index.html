<!doctype html> <html lang=en > <meta charset=UTF-8 > <meta name=viewport  content="width=device-width, initial-scale=1"> <link rel="shortcut icon" type="image/png" href="/TuringModels.jl/assets/favicon.png"/> <link rel=stylesheet  href="/TuringModels.jl/libs/highlight/github.min.css"> <link rel=stylesheet  href="/TuringModels.jl/css/franklin.css"> <title>Glimmer</title> <div class=franklin-content > <div class=top-bar > <a href="/TuringModels.jl/">TuringModels</a> </div> <h1>Glimmer</h1> </div> <div class=franklin-content > <p>In Statistical Rethinking Edition 1, McElreath shows that the R <code>glimmer</code> package introduces weakly regularizing priors by default. This can sometimes lead to nonsense estimates. To fix it, McElreath uses a very weakly informative prior in model <code>m.good</code>.</p> <h2 id=data ><a href="#data" class=header-anchor >Data</a></h2> <pre><code class=language-julia ># Outcome and predictor almost perfectly associated.
x &#61; repeat&#40;&#91;-1&#93;, 9&#41;; append&#33;&#40;x, repeat&#40;&#91;1&#93;,11&#41;&#41;;
y &#61; repeat&#40;&#91;0&#93;, 10&#41;; append&#33;&#40;y, repeat&#40;&#91;1&#93;,10&#41;&#41;;</code></pre> <h2 id=model ><a href="#model" class=header-anchor >Model</a></h2> <pre><code class=language-julia >using Turing

@model m_good_stan&#40;x, y&#41; &#61; begin
    α ~ Normal&#40;0, 10&#41;
    β ~ Normal&#40;0, 10&#41;

    logits &#61; α .&#43; β * x

    y .~ BinomialLogit.&#40;1, logits&#41;
end;</code></pre> <h2 id=output ><a href="#output" class=header-anchor >Output</a></h2> <pre><code class=language-julia >chns &#61; sample&#40;m_good_stan&#40;x, y&#41;, NUTS&#40;&#41;, 1000&#41;</code></pre><pre><code class=plaintext >Chains MCMC chain (1000×14×1 Array{Float64, 3}):

Iterations        = 501:1:1500
Number of chains  = 1
Samples per chain = 1000
Wall duration     = 4.55 seconds
Compute duration  = 4.55 seconds
parameters        = α, β
internals         = lp, n_steps, is_accept, acceptance_rate, log_density, hamiltonian_energy, hamiltonian_energy_error, max_hamiltonian_energy_error, tree_depth, numerical_error, step_size, nom_step_size

Summary Statistics
  parameters      mean       std   naive_se      mcse       ess      rhat   ess_per_sec
      Symbol   Float64   Float64    Float64   Float64   Float64   Float64       Float64

           α   -5.8609    4.5808     0.1449    0.2984   97.1370    1.0024       21.3394
           β    8.6514    4.5616     0.1442    0.3164   95.7486    1.0021       21.0344

Quantiles
  parameters       2.5%     25.0%     50.0%     75.0%     97.5%
      Symbol    Float64   Float64   Float64   Float64   Float64

           α   -17.2687   -8.2588   -5.1852   -2.3055    0.3822
           β     2.5875    5.1591    7.7746   10.9812   19.9557
</code></pre> </p> <pre><code class=language-julia >using StatsPlots

StatsPlots.plot&#40;chns&#41;</code></pre> <p> <img src="/TuringModels.jl/assets/models/glimmer/code/output/chns.svg" alt=""> <h2 id=original_output ><a href="#original_output" class=header-anchor >Original output</a></h2> <pre><code class=language-julia >m_10_x,_results &#61; &quot;
    mean   sd   5.5&#37; 94.5&#37; n_eff Rhat
 a -5.09 4.08 -12.62 -0.25   100 1.00
 b  7.86 4.09   2.96 15.75   104 1.01
&quot;;</code></pre> <div class=page-foot > <div class=copyright > <a href="http://creativecommons.org/licenses/by-sa/4.0/">CC BY-SA 4.0</a> Rob Goedman, Richard Torkar, Rik Huijzer, Martin Trapp and contributors. Last modified: July 20, 2021. Website built with <a href="https://github.com/tlienart/Franklin.jl">Franklin.jl</a> and the <a href="https://julialang.org">Julia programming language</a>. </div> </div> </div> <script src="/TuringModels.jl/libs/highlight/highlight.pack.js"></script> <script>hljs.initHighlightingOnLoad();hljs.configure({tabReplace: ' '});</script>